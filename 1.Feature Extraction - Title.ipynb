{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json 불러와서 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import jpype\n",
    "import glob\n",
    "from random import shuffle\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "data_path = \"data\"\n",
    "#data_path = \"data(test)\"\n",
    "\n",
    "file_list = glob.glob(\"%s/*.json\" % data_path)\n",
    "\n",
    "shuffle(file_list)\n",
    "\n",
    "json_train=[]\n",
    "\n",
    "for json_file_name in file_list:\n",
    "    json_file = json.loads(open(json_file_name).read())\n",
    "    json_train += json_file[\"articles\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json에서 title 형태소 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>istroll</th>\n",
       "      <th>title_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pk</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109057</th>\n",
       "      <td>False</td>\n",
       "      <td>[아이돌_NNP, 마스터_NNG, 는_JX, 이런_MM, 것_NNB, 입니다_VCP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109058</th>\n",
       "      <td>False</td>\n",
       "      <td>[어찌_MAG, 보_VV, 면_EC, 새_MM, 누리_NNG, 당은_NNP+JX, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109059</th>\n",
       "      <td>False</td>\n",
       "      <td>[찌_NNG, 릉_NNG, 찌_NNG, 릉_NNG, 은_JX, 일_NNG, 워_NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109060</th>\n",
       "      <td>False</td>\n",
       "      <td>[k_SL, 리그_NNG, 의_JKG, 근본_NNG, 적_XSN, 문제점_NNG, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109061</th>\n",
       "      <td>False</td>\n",
       "      <td>[자_IC, 우리_NP, 모두_MAG, 댓글_NNG, 활_NNG, 명수_NNG, 마...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109062</th>\n",
       "      <td>False</td>\n",
       "      <td>[일몰_NNG, 짤_VV+ETM, 찍_VV, 어_EC, 봤_VX+EP, 닭_NNG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109063</th>\n",
       "      <td>False</td>\n",
       "      <td>[안녕_NNG, 하_XSV, 세요_EP+EF, ._SF, :_SC, )_SSC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109064</th>\n",
       "      <td>False</td>\n",
       "      <td>[Death_SL, at_SL, a_SL, Funeral_SL, (_SSO, 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109065</th>\n",
       "      <td>False</td>\n",
       "      <td>[그래도_MAJ, 심심_NNG, 할땐_XSV+ETM+NNG+JX, 일_NR, 워_I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109066</th>\n",
       "      <td>False</td>\n",
       "      <td>[[_SSO, 학교_NNG, 소개_NNG, ]_SSC, 소프트웨어_NNG, 개발자_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109067</th>\n",
       "      <td>False</td>\n",
       "      <td>[[_SSO, 정보_NNG, ]_SSC, 소프트웨어_NNG, 개발자_NNG, 를_J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109069</th>\n",
       "      <td>False</td>\n",
       "      <td>[재_XPN, 업_NNG, ]_SSC, 어제_MAG, 그것_NP, 이_JKS, 알_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109070</th>\n",
       "      <td>False</td>\n",
       "      <td>[비하_NNG, 와_JC, 모독_NNG, ._SF]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109071</th>\n",
       "      <td>False</td>\n",
       "      <td>[페북_NNP, 에_JKB, 친구_NNG, 추천_NNG, 은_JX, 어떻게_MAG,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109072</th>\n",
       "      <td>False</td>\n",
       "      <td>[성선설_NNG, vs_SL, 성악설_NNG, 뭘_NP+JKO, 믿_VV, 농_NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109073</th>\n",
       "      <td>False</td>\n",
       "      <td>[도쿄_NNP, 는_JX, 방사능_NNG, 에_JKB, 안전_NNG, 하농_NNG,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109075</th>\n",
       "      <td>True</td>\n",
       "      <td>[게임_NNG, 에니_NNG, 망해_VV+EC, 가_VX, 는_ETM, 이유_NNG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109076</th>\n",
       "      <td>False</td>\n",
       "      <td>[터미네이터_NNP, 5_SN, 언제_MAG, 개봉_NNG, 하나_NR, 농_NNG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109077</th>\n",
       "      <td>False</td>\n",
       "      <td>[부시_NNP, 재선_NNG, 성공_NNG, 당시_NNG, 상황_NNG, ._SF]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109078</th>\n",
       "      <td>False</td>\n",
       "      <td>[이제_MAG, 북한_NNP, 이_JKS, 공산주의_NNG, 를_JKO, 표방_NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109079</th>\n",
       "      <td>False</td>\n",
       "      <td>[[_SSO, 위키_NNP, ]_SSC, 이_MM, 수역_NNG, v_SL, 2_S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109080</th>\n",
       "      <td>False</td>\n",
       "      <td>[혓바늘_NNG, 이_JKS, 돋_VV+EP, 을_ETM, 땐_NNG+JX, 어찌_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109081</th>\n",
       "      <td>False</td>\n",
       "      <td>[[_SSO, 위키_NNP, ]_SSC, 이_MM, 수역_NNG, v_SL, 2_S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109082</th>\n",
       "      <td>False</td>\n",
       "      <td>[쓴_VV+ETM, 글_NNG, 이_JKS, 1000_SN, 개_NNBC, 넘어간_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109083</th>\n",
       "      <td>False</td>\n",
       "      <td>[일단_MAG, 표_NNG, 는_JX, 갖_VX, 다_EC, 붙이_VV, 는_ETM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109084</th>\n",
       "      <td>False</td>\n",
       "      <td>[[_SSO, 속보_NNG, ]_SSC, 檢_SH, ,_SC, '_SY, 문서_NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109085</th>\n",
       "      <td>False</td>\n",
       "      <td>[조중동_NNP, 을_JKO, 19_SN, 금딱지_NNG, 붙였_VV+EP, 음_E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109088</th>\n",
       "      <td>False</td>\n",
       "      <td>[내일_MAG, 학교_NNG, 우째_MAG, 가농_NNP, ._SF, ..._SY,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109089</th>\n",
       "      <td>False</td>\n",
       "      <td>[[_SSO, 메이플_NNP, ]_SSC, 랑_JKB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109090</th>\n",
       "      <td>False</td>\n",
       "      <td>[애플_NNP, 스티커_NNG, 는_JX, 용도_NNG, 가_JKS, 대체_MAG,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142569</th>\n",
       "      <td>False</td>\n",
       "      <td>[쿨_NNG, ~_SY, 냥_NNBC, !_SF, !_SF]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142570</th>\n",
       "      <td>True</td>\n",
       "      <td>[밥_NNG, 친구_NNG, 라도_VCP+EC, 만들_VV, 어야지_EC, ~_SY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142571</th>\n",
       "      <td>False</td>\n",
       "      <td>[The_SL, Worker_SL, '_SY, s_SL, Freedom_SL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142572</th>\n",
       "      <td>False</td>\n",
       "      <td>[군대_NNG, 가_JKS, 면_NNG, ._SF, .._SY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142573</th>\n",
       "      <td>True</td>\n",
       "      <td>[난_NP+JX, 심리_NNG, 치료사_NNG, ,_SC, 변호사_NNG, ,_SC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142574</th>\n",
       "      <td>False</td>\n",
       "      <td>[농_NNG, 체_NNB, 는_JX, 생각_NNG, 할수록_XSV+EC, 귀엽_VA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142575</th>\n",
       "      <td>False</td>\n",
       "      <td>[왜_MAG, GLBT_SL, 가_JKC, 아니_VCN, 라_EC, LGBT_SL,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142576</th>\n",
       "      <td>False</td>\n",
       "      <td>[햄버거_NNP, 랑_JC, 맥주_NNG, 랑_JKB, 야식_NNG, 으로_JKB,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142577</th>\n",
       "      <td>True</td>\n",
       "      <td>[내_NP, 가_JKS, 놓아주_VV, 면_EC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142578</th>\n",
       "      <td>False</td>\n",
       "      <td>[해냈_VV+EP, 다_EF, ,_SC, 해냈_VV+EP, 어_EF, ,_SC, 창...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142579</th>\n",
       "      <td>False</td>\n",
       "      <td>[건치_NNG, 미남_NNG, ㅋㅋ_UNKNOWN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142581</th>\n",
       "      <td>False</td>\n",
       "      <td>[일간_NNG, 워스트_NNP, DDT_SL, 뉴스_NNG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142582</th>\n",
       "      <td>False</td>\n",
       "      <td>[차라리_MAG, 문창극_NNP, 씨_NNB, 총리_NNG, 되게_MAG, 밀_VV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142583</th>\n",
       "      <td>False</td>\n",
       "      <td>[포카_NNP, 칩_NNG, 의_JKG, 진실_NNG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142584</th>\n",
       "      <td>True</td>\n",
       "      <td>[빗방울_NNG, ._SF, .._SY]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142585</th>\n",
       "      <td>False</td>\n",
       "      <td>[문창극_NNP, \"_SY, KBS_SL, 보도_NNG, 사실_NNG, 과_JKB,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142586</th>\n",
       "      <td>False</td>\n",
       "      <td>[문창극_NNP, 님_XSN, 이_JKS, 십_NR, 알_VV, 단_ETM, 총수_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142588</th>\n",
       "      <td>False</td>\n",
       "      <td>[아_IC, ._SF, .._SY, 미치_VV, 겠_EP, 네요_EF, ._SF]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142589</th>\n",
       "      <td>False</td>\n",
       "      <td>[시리_NNG, 의_JKG, 드립_NNG, 력_XSN, ._SY, jpg_SL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142590</th>\n",
       "      <td>False</td>\n",
       "      <td>[‘_SY, 문창극_NNP, 참극_NNG, ’…_SY, 침몰_NNG, 한_XSA+E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142592</th>\n",
       "      <td>False</td>\n",
       "      <td>[극_NNG, 혐_UNKNOWN, )_SSC, 현재_NNG, SNS_SL, 문창극_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142593</th>\n",
       "      <td>False</td>\n",
       "      <td>[우리_NP, 도_JX, 일_NNG, 베_NNG, 에_JKB, 복수_NNG, 하_X...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142594</th>\n",
       "      <td>False</td>\n",
       "      <td>[뭔가_NP+VCP+EC, 이상_NNG, 하_XSV, 다_EC, 농_NNG, ._S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142595</th>\n",
       "      <td>False</td>\n",
       "      <td>[복_NNG, 돌_NNG, 방송_NNG, 하_XSV, 는_ETM, 거_NNB, 어떻...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142596</th>\n",
       "      <td>False</td>\n",
       "      <td>[새_MM, 눌_NNG, 당_XSN, 이_JKS, 자꾸_MAG, 만_JX, 집권_N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142597</th>\n",
       "      <td>False</td>\n",
       "      <td>[표정_NNG, 이_JKS, 어두운_VA+ETM, 그녀_NP, 를_JKO, 보_VV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142598</th>\n",
       "      <td>False</td>\n",
       "      <td>[[_SSO, 극_NNG, 혐_UNKNOWN, ]_SSC, 트롤_NNG, 밭_NNG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142599</th>\n",
       "      <td>False</td>\n",
       "      <td>[일_NR, 베_NNG, 아이_NNG, 들_XSN, 이_JKS, 자꾸_MAG, 본질...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142600</th>\n",
       "      <td>False</td>\n",
       "      <td>[나농_NNG, 혹시_MAG, 운하_NNG, 했_XSV+EP, 농_XR, ?_SF]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142601</th>\n",
       "      <td>False</td>\n",
       "      <td>[모르_VV, 는_ETM, 사람_NNG, 이_JKS, 나_NP, 에게_JKB, 카카...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172044 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       istroll                                          title_pos\n",
       "pk                                                               \n",
       "109057   False  [아이돌_NNP, 마스터_NNG, 는_JX, 이런_MM, 것_NNB, 입니다_VCP...\n",
       "109058   False  [어찌_MAG, 보_VV, 면_EC, 새_MM, 누리_NNG, 당은_NNP+JX, ...\n",
       "109059   False  [찌_NNG, 릉_NNG, 찌_NNG, 릉_NNG, 은_JX, 일_NNG, 워_NN...\n",
       "109060   False  [k_SL, 리그_NNG, 의_JKG, 근본_NNG, 적_XSN, 문제점_NNG, ...\n",
       "109061   False  [자_IC, 우리_NP, 모두_MAG, 댓글_NNG, 활_NNG, 명수_NNG, 마...\n",
       "109062   False     [일몰_NNG, 짤_VV+ETM, 찍_VV, 어_EC, 봤_VX+EP, 닭_NNG]\n",
       "109063   False       [안녕_NNG, 하_XSV, 세요_EP+EF, ._SF, :_SC, )_SSC]\n",
       "109064   False  [Death_SL, at_SL, a_SL, Funeral_SL, (_SSO, 200...\n",
       "109065   False  [그래도_MAJ, 심심_NNG, 할땐_XSV+ETM+NNG+JX, 일_NR, 워_I...\n",
       "109066   False  [[_SSO, 학교_NNG, 소개_NNG, ]_SSC, 소프트웨어_NNG, 개발자_...\n",
       "109067   False  [[_SSO, 정보_NNG, ]_SSC, 소프트웨어_NNG, 개발자_NNG, 를_J...\n",
       "109069   False  [재_XPN, 업_NNG, ]_SSC, 어제_MAG, 그것_NP, 이_JKS, 알_...\n",
       "109070   False                       [비하_NNG, 와_JC, 모독_NNG, ._SF]\n",
       "109071   False  [페북_NNP, 에_JKB, 친구_NNG, 추천_NNG, 은_JX, 어떻게_MAG,...\n",
       "109072   False  [성선설_NNG, vs_SL, 성악설_NNG, 뭘_NP+JKO, 믿_VV, 농_NN...\n",
       "109073   False  [도쿄_NNP, 는_JX, 방사능_NNG, 에_JKB, 안전_NNG, 하농_NNG,...\n",
       "109075    True    [게임_NNG, 에니_NNG, 망해_VV+EC, 가_VX, 는_ETM, 이유_NNG]\n",
       "109076   False  [터미네이터_NNP, 5_SN, 언제_MAG, 개봉_NNG, 하나_NR, 농_NNG...\n",
       "109077   False     [부시_NNP, 재선_NNG, 성공_NNG, 당시_NNG, 상황_NNG, ._SF]\n",
       "109078   False  [이제_MAG, 북한_NNP, 이_JKS, 공산주의_NNG, 를_JKO, 표방_NN...\n",
       "109079   False  [[_SSO, 위키_NNP, ]_SSC, 이_MM, 수역_NNG, v_SL, 2_S...\n",
       "109080   False  [혓바늘_NNG, 이_JKS, 돋_VV+EP, 을_ETM, 땐_NNG+JX, 어찌_...\n",
       "109081   False  [[_SSO, 위키_NNP, ]_SSC, 이_MM, 수역_NNG, v_SL, 2_S...\n",
       "109082   False  [쓴_VV+ETM, 글_NNG, 이_JKS, 1000_SN, 개_NNBC, 넘어간_...\n",
       "109083   False  [일단_MAG, 표_NNG, 는_JX, 갖_VX, 다_EC, 붙이_VV, 는_ETM...\n",
       "109084   False  [[_SSO, 속보_NNG, ]_SSC, 檢_SH, ,_SC, '_SY, 문서_NN...\n",
       "109085   False  [조중동_NNP, 을_JKO, 19_SN, 금딱지_NNG, 붙였_VV+EP, 음_E...\n",
       "109088   False  [내일_MAG, 학교_NNG, 우째_MAG, 가농_NNP, ._SF, ..._SY,...\n",
       "109089   False                     [[_SSO, 메이플_NNP, ]_SSC, 랑_JKB]\n",
       "109090   False  [애플_NNP, 스티커_NNG, 는_JX, 용도_NNG, 가_JKS, 대체_MAG,...\n",
       "...        ...                                                ...\n",
       "142569   False                  [쿨_NNG, ~_SY, 냥_NNBC, !_SF, !_SF]\n",
       "142570    True    [밥_NNG, 친구_NNG, 라도_VCP+EC, 만들_VV, 어야지_EC, ~_SY]\n",
       "142571   False        [The_SL, Worker_SL, '_SY, s_SL, Freedom_SL]\n",
       "142572   False                [군대_NNG, 가_JKS, 면_NNG, ._SF, .._SY]\n",
       "142573    True  [난_NP+JX, 심리_NNG, 치료사_NNG, ,_SC, 변호사_NNG, ,_SC...\n",
       "142574   False  [농_NNG, 체_NNB, 는_JX, 생각_NNG, 할수록_XSV+EC, 귀엽_VA...\n",
       "142575   False  [왜_MAG, GLBT_SL, 가_JKC, 아니_VCN, 라_EC, LGBT_SL,...\n",
       "142576   False  [햄버거_NNP, 랑_JC, 맥주_NNG, 랑_JKB, 야식_NNG, 으로_JKB,...\n",
       "142577    True                        [내_NP, 가_JKS, 놓아주_VV, 면_EC]\n",
       "142578   False  [해냈_VV+EP, 다_EF, ,_SC, 해냈_VV+EP, 어_EF, ,_SC, 창...\n",
       "142579   False                       [건치_NNG, 미남_NNG, ㅋㅋ_UNKNOWN]\n",
       "142581   False                  [일간_NNG, 워스트_NNP, DDT_SL, 뉴스_NNG]\n",
       "142582   False  [차라리_MAG, 문창극_NNP, 씨_NNB, 총리_NNG, 되게_MAG, 밀_VV...\n",
       "142583   False                     [포카_NNP, 칩_NNG, 의_JKG, 진실_NNG]\n",
       "142584    True                             [빗방울_NNG, ._SF, .._SY]\n",
       "142585   False  [문창극_NNP, \"_SY, KBS_SL, 보도_NNG, 사실_NNG, 과_JKB,...\n",
       "142586   False  [문창극_NNP, 님_XSN, 이_JKS, 십_NR, 알_VV, 단_ETM, 총수_...\n",
       "142588   False      [아_IC, ._SF, .._SY, 미치_VV, 겠_EP, 네요_EF, ._SF]\n",
       "142589   False       [시리_NNG, 의_JKG, 드립_NNG, 력_XSN, ._SY, jpg_SL]\n",
       "142590   False  [‘_SY, 문창극_NNP, 참극_NNG, ’…_SY, 침몰_NNG, 한_XSA+E...\n",
       "142592   False  [극_NNG, 혐_UNKNOWN, )_SSC, 현재_NNG, SNS_SL, 문창극_...\n",
       "142593   False  [우리_NP, 도_JX, 일_NNG, 베_NNG, 에_JKB, 복수_NNG, 하_X...\n",
       "142594   False  [뭔가_NP+VCP+EC, 이상_NNG, 하_XSV, 다_EC, 농_NNG, ._S...\n",
       "142595   False  [복_NNG, 돌_NNG, 방송_NNG, 하_XSV, 는_ETM, 거_NNB, 어떻...\n",
       "142596   False  [새_MM, 눌_NNG, 당_XSN, 이_JKS, 자꾸_MAG, 만_JX, 집권_N...\n",
       "142597   False  [표정_NNG, 이_JKS, 어두운_VA+ETM, 그녀_NP, 를_JKO, 보_VV...\n",
       "142598   False  [[_SSO, 극_NNG, 혐_UNKNOWN, ]_SSC, 트롤_NNG, 밭_NNG...\n",
       "142599   False  [일_NR, 베_NNG, 아이_NNG, 들_XSN, 이_JKS, 자꾸_MAG, 본질...\n",
       "142600   False     [나농_NNG, 혹시_MAG, 운하_NNG, 했_XSV+EP, 농_XR, ?_SF]\n",
       "142601   False  [모르_VV, 는_ETM, 사람_NNG, 이_JKS, 나_NP, 에게_JKB, 카카...\n",
       "\n",
       "[172044 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab()\n",
    "\n",
    "labeled_train = []\n",
    "\n",
    "for cnt, article in enumerate(json_train):\n",
    "    \n",
    "    if cnt % 10000 == 0:\n",
    "        print cnt\n",
    "\n",
    "    labeled_train.append({\n",
    "            \"istroll\": article[\"is_troll\"],\n",
    "            \"title_pos\": [\"%s_%s\" % (word, pos) for word, pos in mecab.pos(article[\"title\"])],\n",
    "            \"pk\": article[\"pk\"]\n",
    "        })\n",
    "    \n",
    "labeled_train = pd.DataFrame.from_dict(labeled_train)\n",
    "labeled_train = labeled_train.set_index('pk')\n",
    "\n",
    "labeled_train = pd.DataFrame.from_dict(labeled_train)\n",
    "labeled_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def make_bag_of_words(labeled_train, max_features, col_name):\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None,\n",
    "                                stop_words = None, max_features=max_features)\n",
    "    \n",
    "    sentences = labeled_train[col_name].apply(lambda x:\" \".join(x))\n",
    "    train_data_features = vectorizer.fit_transform(sentences).toarray()\n",
    "\n",
    "    col = [\"bow_%s_%s\" % (col_name, data) for data in vectorizer.get_feature_names()]\n",
    "    #col = [\"bow%s%s\" % (col_name, str(i)) for  in range(0, max_features)]\n",
    "    df_bow = pd.DataFrame(train_data_features, columns = col, index=labeled_train.index)\n",
    "    \n",
    "    labeled_train = pd.concat([labeled_train, df_bow],axis=1)\n",
    "    \n",
    "    return labeled_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.corpora import TextCorpus, MmCorpus, Dictionary\n",
    "from nltk.corpus import stopwords\n",
    "from optparse import OptionParser\n",
    "\n",
    "def make_lda(train, keep_n, num_topics, col_name):\n",
    "\n",
    "    data = train[col_name]\n",
    "\n",
    "    dictionary = corpora.Dictionary(data)\n",
    "    dictionary.filter_extremes(keep_n=keep_n)\n",
    "\n",
    "    corpus = [dictionary.doc2bow(text) for text in data]\n",
    "\n",
    "    print(\"Make Lda..\")\n",
    "\n",
    "#    lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, chunksize=1000, passes=1,distributed = True)\n",
    "    lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, chunksize=1000, passes=1)\n",
    "    \n",
    "    num = len(train)    \n",
    "    df = []\n",
    "    \n",
    "    for i in range(0,num):\n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "        \n",
    "        temp = [i[1] for i in lda.get_document_topics(corpus[i],minimum_probability=0)]\n",
    "        #temp = max(lda.get_document_topics(corpus[i]),key=lambda item:item[1])[0]\n",
    "        df.append(temp)\n",
    "    \n",
    "    col = [\"lda_%s_%d\" % (col_name, data) for data in range(0, num_topics)]\n",
    "    df = pd.DataFrame(df, columns = col)\n",
    "    df.index = train.index\n",
    "    \n",
    "    train = pd.concat([train, df], axis=1)\n",
    "        \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "def make_feature_vec(words, model, num_features):\n",
    "    \n",
    "    feature_vec = np.zeros((num_features,), dtype = \"float32\")\n",
    "    \n",
    "    nwords = 0\n",
    "    \n",
    "    index2word_set = set(model.index2word)\n",
    "    \n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1.\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "    \n",
    "    if nwords != 0:\n",
    "        feature_vec = np.divide(feature_vec, nwords)\n",
    "    \n",
    "    return feature_vec\n",
    "\n",
    "def get_avg_feature_vecs(texts, model, num_features):\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    text_feature_vecs = np.zeros((len(texts), num_features), dtype = \"float32\")\n",
    "    \n",
    "    for i, text in enumerate(texts):\n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            print(i)\n",
    "        \n",
    "        text_feature_vecs[i] = make_feature_vec(text , model, num_features)\n",
    "        \n",
    "    return text_feature_vecs\n",
    "\n",
    "def make_word2vec(train, col_name):\n",
    "    num_features = 300\n",
    "    min_word_count = 40\n",
    "    num_workers = 4\n",
    "    context = 10\n",
    "    downsampling = 1e-3\n",
    "    \n",
    "    sentences = \" \".join(train[col_name].apply(lambda x:\" \".join(x)))\n",
    "    \n",
    "    model = word2vec.Word2Vec(sentences, workers = num_workers, size = num_features,\\\n",
    "                             min_count = min_word_count, window = context, sample = downsampling)\n",
    "    \n",
    "    col = [\"word2vec_%s_%d\" % (col_name, data) for data in range(0, num_features)]\n",
    "    \n",
    "    train_feature = get_avg_feature_vecs(train[col_name].apply(lambda x:\" \".join(x)), model, num_features)\n",
    "    train_feature = pd.DataFrame(train_feature, index = train.index, columns = col)\n",
    "    \n",
    "    train = pd.concat([train, train_feature], axis = 1)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "CPU times: user 1min 35s, sys: 38.4 s, total: 2min 13s\n",
      "Wall time: 1min 46s\n"
     ]
    }
   ],
   "source": [
    "max_features = 1000\n",
    "#%time labeled_train = make_lda(labeled_train, 5000, 1000, \"title_pos\")\n",
    "#%time labeled_train = make_bag_of_words(labeled_train, 300, \"title_pos\")\n",
    "\n",
    "%time labeled_train = make_word2vec(labeled_train, \"title_pos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predictor, model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "label = 'istroll'\n",
    "pre = labeled_train.columns.drop(['title_pos', label])\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=10, n_jobs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.572528019398\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "cv_value = 3\n",
    "\n",
    "scores = cross_validation.cross_val_score(model, labeled_train[pre], labeled_train[label], cv=cv_value, scoring=\"roc_auc\")\n",
    "cv_result = scores.mean()\n",
    "\n",
    "print(cv_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Result\n",
    "  * title의 morphs를 bag of words로 변환 (feature : 1,000개) - 0.612752193303\n",
    "  * title의 pos를 bag of words로 변환 (feature : 1,000개) - 0.630053006037\n",
    "  * 데이터를 셔플하고 title의 pos를 bag of words로 변환 (feature : 1,000개) - 0.658894903487\n",
    "  \n",
    "  * title의 pos를 LDA로 변환 (keep_n : 5,000, num_topics : 1,000) - 0.592446285012\n",
    "  \n",
    "  * title의 pos를 word2vec으로 변환 (num_features = 300) 0.582477335724"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(labeled_train[pre], open(\"title_%d.p\" % max_features, \"wb\"), protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
