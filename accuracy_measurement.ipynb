{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 각 모델별 parameter를 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = \"bow\"\n",
    "\n",
    "num_author = [100, 200, 500, 1000]\n",
    "num_title = [100, 200, 500, 1000]\n",
    "num_text = [500, 1000, 2000, 5000]\n",
    "\n",
    "# num_author = [100]\n",
    "# num_title = [600]\n",
    "# num_text = [1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = \"lda\"\n",
    "\n",
    "num_author = [100, 200, 500, 1000]\n",
    "num_title = [100, 200, 500, 1000]\n",
    "num_text = [200, 500, 1000, 2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = \"word2vec\"\n",
    "\n",
    "num_author = [100, 200, 300, 500]\n",
    "num_title = [100, 200, 300, 500]\n",
    "num_text = [100, 200, 500, 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameter별로 파일을 읽어옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "author_forum_p = []\n",
    "title_p = []\n",
    "text_p = []\n",
    "\n",
    "for num in num_author:\n",
    "    author_forum_p.append(pickle.load(open(\"%s/author, forum_%d.p\" % (model, num), \"rb\")))\n",
    "for num in num_title:\n",
    "    title_p.append(pickle.load(open(\"%s/title_%d.p\" % (model, num), \"rb\")))\n",
    "for num in num_text:\n",
    "    text_p.append(pickle.load(open(\"%s/text_%d.p\" % (model, num), \"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = []\n",
    "for author_cnt, author in enumerate(num_author):\n",
    "    train.append([])\n",
    "    for title_cnt, title in enumerate(num_title):\n",
    "        train[author_cnt].append([])\n",
    "        for text_cnt, text in enumerate(num_text):\n",
    "            train[author_cnt][title_cnt].append(pd.concat([author_forum_p[author_cnt], title_p[title_cnt], text_p[text_cnt]], axis = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Score와 Cross Validation Score 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "label = 'istroll'\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 10, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_score = []\n",
    "cv_score = []\n",
    "for author_cnt, author in enumerate(num_author):\n",
    "    train_score.append([])\n",
    "    cv_score.append([])\n",
    "    for title_cnt, title in enumerate(num_title):\n",
    "        train_score[author_cnt].append([])\n",
    "        cv_score[author_cnt].append([])\n",
    "        for text_cnt, text in enumerate(num_text):\n",
    "            predictors = train[author_cnt][title_cnt][text_cnt].columns.drop([label])\n",
    "            model.fit(train[author_cnt][title_cnt][text_cnt][predictors], train[author_cnt][title_cnt][text_cnt][label])\n",
    "            predicted = model.predict_proba(train[author_cnt][title_cnt][text_cnt][predictors])\n",
    "            train_score[author_cnt][title_cnt].append(roc_auc_score(train[author_cnt][title_cnt][text_cnt][label], predicted.T[1]))\n",
    "            cv_score[author_cnt][title_cnt].append(np.mean(cross_val_score(model, train[author_cnt][title_cnt][text_cnt][predictors], train[author_cnt][title_cnt][text_cnt][label], scoring='roc_auc', cv=3, n_jobs=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.99943534726143413]]]\n",
      "[[[0.66981684981684975]]]\n"
     ]
    }
   ],
   "source": [
    "print train_score\n",
    "print cv_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
