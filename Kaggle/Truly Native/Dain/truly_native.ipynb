{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(\"Data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_keys = dict([a[1] for a in train_labels.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_files = set(pd.read_csv('Data/sampleSubmission.csv').file.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "PATH_TO_DATA = \"/Users/Nerrtica/Documents/Study/3rdYear/SWMaestro/2ndProject/Kaggle/TrulyNative?/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# put in the path to the kaggle data\n",
    "PATH_TO_JSON = \"Data/parsed_data\"\n",
    "PATH_TO_TRAIN_LABELS = \"Data/train.csv\"\n",
    "PATH_TO_TEST_LABELS = \"Data/sampleSubmission.csv\"\n",
    "\n",
    "# a simple method to create some basic features on an SFrame\n",
    "def create_count_features(sf):\n",
    "    sf['num_images'] = sf['images'].apply(lambda x: len(x))\n",
    "    sf['num_links'] = sf['links'].apply(lambda x: len(x))\n",
    "    sf['num_clean_chars'] = sf['text_clean'].apply(lambda x: len(x))\n",
    "    return sf\n",
    "\n",
    "# a simple method to clean the text within an html response\n",
    "def clean_text(sf):\n",
    "    sf['text_clean'] = sf['text'].apply(lambda x:\n",
    "        #re.sub(r'[\\n\\t,.:;()\\-\\/]+', ' ', ' '.join(x)))\n",
    "        re.sub('[^a-zA-Z]', ' ', ' '.join(x)))\n",
    "    sf['text_clean'] = sf['text_clean'].apply(lambda x: re.sub(r'\\s{2,}', ' ', x))\n",
    "    sf['text_clean'] = sf['text_clean'].apply(lambda x: x.strip())\n",
    "    return sf\n",
    "\n",
    "# a wrapper method around the 2 methods above\n",
    "def process_dataframe(sf):\n",
    "    sf = clean_text(sf)\n",
    "    sf = create_count_features(sf)\n",
    "    return sf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named graphlab",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4a710214f762>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphlab\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named graphlab"
     ]
    }
   ],
   "source": [
    "import graphlab as gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] This trial license of GraphLab Create is assigned to nerrtica@naver.com and will expire on November 01, 2015. Please contact trial@dato.com for licensing options or to request a free non-commercial license for personal or academic use.\n",
      "\n",
      "[INFO] Start server at: ipc:///tmp/graphlab_server-673 - Server binary: /Users/Nerrtica/.graphlab/anaconda/lib/python2.7/site-packages/graphlab/unity_server - Server log: /tmp/graphlab_server_1444010490.log\n",
      "[INFO] GraphLab Server Version: 1.6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Finished parsing file /Users/Nerrtica/Documents/Study/3rdYear/SWMaestro/2ndProject/Kaggle/TrulyNative?/Data/parsed_data/chunk0.json\n",
      "PROGRESS: Parsing completed. Parsed 100 lines in 0.654601 secs.\n",
      "------------------------------------------------------\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[dict]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "PROGRESS: Read 1936 lines. Lines per second: 1651.18\n",
      "PROGRESS: Read 15153 lines. Lines per second: 2419.7\n",
      "PROGRESS: Read 29470 lines. Lines per second: 2540.09\n",
      "PROGRESS: Read 43765 lines. Lines per second: 2540.51\n",
      "PROGRESS: Read 57315 lines. Lines per second: 2576.51\n",
      "PROGRESS: Finished parsing file /Users/Nerrtica/Documents/Study/3rdYear/SWMaestro/2ndProject/Kaggle/TrulyNative?/Data/parsed_data/chunk0.json\n",
      "PROGRESS: Read 69376 lines. Lines per second: 2534.89\n",
      "PROGRESS: Unable to parse line \"                                                                                         \\n\\n                                                                                                                                                                   ...\"\n",
      "PROGRESS: Read 82194 lines. Lines per second: 2535.53\n",
      "PROGRESS: Read 95933 lines. Lines per second: 2522.03\n",
      "PROGRESS: Read 109188 lines. Lines per second: 2529.51\n",
      "PROGRESS: Read 123370 lines. Lines per second: 2556.25\n",
      "PROGRESS: 1 lines failed to parse correctly\n",
      "PROGRESS: Finished parsing file /Users/Nerrtica/Documents/Study/3rdYear/SWMaestro/2ndProject/Kaggle/TrulyNative?/Data/parsed_data/chunk1.json\n",
      "PROGRESS: Read 136747 lines. Lines per second: 2559.07\n",
      "PROGRESS: Read 150539 lines. Lines per second: 2566.22\n",
      "PROGRESS: Read 162841 lines. Lines per second: 2558.49\n",
      "PROGRESS: Read 177162 lines. Lines per second: 2565.2\n",
      "PROGRESS: Read 191249 lines. Lines per second: 2566.78\n",
      "PROGRESS: 1 lines failed to parse correctly\n",
      "PROGRESS: Finished parsing file /Users/Nerrtica/Documents/Study/3rdYear/SWMaestro/2ndProject/Kaggle/TrulyNative?/Data/parsed_data/chunk2.json\n",
      "PROGRESS: Read 204155 lines. Lines per second: 2558.59\n",
      "PROGRESS: Read 216644 lines. Lines per second: 2553.09\n",
      "PROGRESS: Read 230630 lines. Lines per second: 2555.01\n",
      "PROGRESS: Read 244273 lines. Lines per second: 2555.93\n",
      "PROGRESS: Read 257032 lines. Lines per second: 2556.38\n",
      "PROGRESS: 1 lines failed to parse correctly\n",
      "PROGRESS: Finished parsing file /Users/Nerrtica/Documents/Study/3rdYear/SWMaestro/2ndProject/Kaggle/TrulyNative?/Data/parsed_data/chunk3.json\n",
      "PROGRESS: Read 269767 lines. Lines per second: 2555.6\n",
      "PROGRESS: Read 281995 lines. Lines per second: 2548.81\n",
      "PROGRESS: Read 294823 lines. Lines per second: 2550.52\n",
      "PROGRESS: Read 308450 lines. Lines per second: 2550.36\n",
      "PROGRESS: Read 322960 lines. Lines per second: 2556.5\n",
      "PROGRESS: 1 lines failed to parse correctly\n",
      "PROGRESS: Finished parsing file /Users/Nerrtica/Documents/Study/3rdYear/SWMaestro/2ndProject/Kaggle/TrulyNative?/Data/parsed_data/chunk4.json\n",
      "PROGRESS: Read 337302 lines. Lines per second: 2556.63\n",
      "PROGRESS: Read 351214 lines. Lines per second: 2558.71\n",
      "PROGRESS: Read 364648 lines. Lines per second: 2554.44\n",
      "PROGRESS: Read 378315 lines. Lines per second: 2551.84\n",
      "PROGRESS: Read 392683 lines. Lines per second: 2555.79\n",
      "PROGRESS: 1 lines failed to parse correctly\n",
      "PROGRESS: Finished parsing file /Users/Nerrtica/Documents/Study/3rdYear/SWMaestro/2ndProject/Kaggle/TrulyNative?/Data/parsed_data/chunk5.json\n",
      "PROGRESS: Parsing completed. Parsed 404074 lines in 157.506 secs.\n"
     ]
    }
   ],
   "source": [
    "# read json blocks from path PATH_TO_JSON\n",
    "sf = gl.SFrame.read_csv(PATH_TO_JSON, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sf = sf.unpack('X1',column_name_prefix='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Finished parsing file /Users/Nerrtica/Documents/Study/3rdYear/SWMaestro/2ndProject/Kaggle/TrulyNative?/Data/train.csv\n",
      "PROGRESS: Parsing completed. Parsed 100 lines in 0.277896 secs.\n",
      "------------------------------------------------------\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "PROGRESS: Finished parsing file /Users/Nerrtica/Documents/Study/3rdYear/SWMaestro/2ndProject/Kaggle/TrulyNative?/Data/train.csv\n",
      "PROGRESS: Parsing completed. Parsed 337024 lines in 0.225021 secs.\n",
      "PROGRESS: Finished parsing file /Users/Nerrtica/Documents/Study/3rdYear/SWMaestro/2ndProject/Kaggle/TrulyNative?/Data/sampleSubmission.csv\n",
      "PROGRESS: Parsing completed. Parsed 100 lines in 0.057248 secs.\n",
      "------------------------------------------------------\n",
      "Inferred types from first line of file as \n",
      "column_type_hints=[str,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n",
      "PROGRESS: Finished parsing file /Users/Nerrtica/Documents/Study/3rdYear/SWMaestro/2ndProject/Kaggle/TrulyNative?/Data/sampleSubmission.csv\n",
      "PROGRESS: Parsing completed. Parsed 66772 lines in 0.05164 secs.\n"
     ]
    }
   ],
   "source": [
    "# read train and test labels from paths PATH_TO_TRAIN_LABELS and PATH_TO_TEST_LABELS\n",
    "train_labels = gl.SFrame.read_csv(PATH_TO_TRAIN_LABELS)\n",
    "test_labels = gl.SFrame.read_csv(PATH_TO_TEST_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a new columns \"id\" from parsing urlId and drop file columns\n",
    "train_labels['id'] = train_labels['file'].apply(lambda x: str(x.split('_')[0] ))\n",
    "train_labels = train_labels.remove_column('file')\n",
    "test_labels['id'] = test_labels['file'].apply(lambda x: str(x.split('_')[0] ))\n",
    "test_labels = test_labels.remove_column('file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join labels with html data from training and testing SFrames\n",
    "train = train_labels.join(sf, on='id', how='left')\n",
    "test = test_labels.join(sf, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call wrapper method process_dataframe on train/test\n",
    "train = process_dataframe(train)\n",
    "test = process_dataframe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bow_trn = gl.text_analytics.count_words(train['text_clean'])\n",
    "bow_trn = bow_trn.dict_trim_by_keys(gl.text_analytics.stopwords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['bow'] = bow_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bow_tst = gl.text_analytics.count_words(test['text_clean'])\n",
    "bow_tst = bow_tst.dict_trim_by_keys(gl.text_analytics.stopwords())\n",
    "\n",
    "test['bow'] = bow_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphlab.toolkits.feature_engineering import TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a TFIDF Transformer that is fit on your training data and transform both training and testing data\n",
    "encoder = gl.feature_engineering.create(train, TFIDF('bow', output_column_name='tfidf'))\n",
    "train = encoder.transform(train)\n",
    "test = encoder.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = gl.random_forest_classifier.create(train, num_trees = 100, target = 'sponsored', features = ['tfidf'], class_weights = 'auto', validation_set = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = test.dropna()\n",
    "ypred = model.predict(test, output_type = 'probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create submission.csv\n",
    "submission = gl.SFrame()\n",
    "submission['sponsored'] = ypred \n",
    "submission['file'] = test['id'].apply(lambda x: x + '_raw_html.txt')\n",
    "submission.save('Data/result.csv', format='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
